"""
"""

import functools
import logging
import mesos
import os
import progressbar
import StringIO
import tarfile
import tempfile
import threading
import time
import uuid

from fs.osfs import OSFS
from fs.s3fs import S3FS

from Queue import Queue
from urlparse import urlparse
from ddocker import subcommand
from ddocker.parser import parse_dockerfile
from ddocker.proto import ddocker_pb2
from ddocker.proto import mesos_pb2

logger = logging.getLogger("ddocker.build")


def args(parser):
    parser.add_argument("dockerfile", action="append")

    # Isolation
    group = parser.add_argument_group("isolation")
    group.add_argument("--cpu-limit", default=1.0,
                       help="CPU allocated to building the image")
    group.add_argument("--mem-limit", default=256,
                       help="Memory allocated to building the image (mb)")

    # Arguments for the staging filesystem
    group = parser.add_argument_group("fs")
    group.add_argument("--staging-uri", default="/tmp/ddocker",
                       help="The URI to use as a base directory for staging files.")
    group.add_argument("--s3-access-key", default=os.environ.get("AWS_ACCESS_KEY_ID"),
                       help="Access key for using the S3 filesystem")
    group.add_argument("--s3-secret-key", default=os.environ.get("AWS_SECRET_ACCESS_KEY"),
                       help="Secret key for using the S3 filesystem")


@subcommand("build", callback=args)
def main(args):

    logger.info("Building docker image from %s", args.dockerfile)

    task_queue = Queue()

    # Launch the mesos framework
    framework = mesos_pb2.FrameworkInfo()
    framework.user = ""  # Mesos can select the user
    framework.name = "ddocker"
    framework.failover_timeout = 300  # Timeout after 300 seconds

    # Figure out the framework info from an existing checkpoint
    if args.checkpoint and os.path.exists(args.checkpoint):
        with open(args.checkpoint) as cp:
            checkpoint = ddocker_pb2.Checkpoint()
            ddocker_pb2.Checkpoint.ParseFromString(
                checkpoint, cp.read()
            )

            if not checkpoint.frameworkId:
                raise RuntimeError("No framework ID in the checkpoint")

            logger.info("Registering with checkpoint framework ID %s", checkpoint.frameworkId)
            framework.id.value = checkpoint.frameworkId

    # Kick off the scheduler driver
    scheduler = Scheduler(
        task_queue,
        args.checkpoint,
        args.cpu_limit,
        args.mem_limit,
        args
    )
    driver = mesos.MesosSchedulerDriver(
        scheduler, framework, args.mesos_master
    )

    # Put the task onto the queue
    for dockerfile in args.dockerfile:
        task_queue.put(dockerfile)

    thread = threading.Thread(target=driver.run)
    thread.setDaemon(True)
    thread.start()

    # Wait here until the tasks are done
    while thread.isAlive():
        time.sleep(0.5)


def make_build_context(output, context_root, dockerfile):
    """Generate and return a compressed tar archive of the build context."""

    dockerfile = parse_dockerfile(dockerfile)

    tar = tarfile.open(mode="w:gz", fileobj=output)
    for idx, (cmd, instruction) in enumerate(dockerfile.instructions):
        if cmd == "ADD":
            local_path, remote_path = instruction
            tar_path = str(idx)

            if not local_path.startswith("/"):
                local_path = os.path.join(context_root, local_path)
            local_path = os.path.abspath(local_path)

            logger.debug("Adding path %s to tar at %s", local_path, tar_path)
            tar.add(local_path, arcname=tar_path)
            dockerfile.instructions[idx] = (cmd, (tar_path, remote_path))

    # Write the modified dockerfile into the tar also
    buildfile = StringIO.StringIO()
    buildfile.write("# Generated by ddocker\n")

    for cmd, instructions in dockerfile.instructions:
        line = "%s %s" % (cmd, " ".join(instructions))

        logger.debug("Added command %r to new dockerfile", line)
        buildfile.write("%s\n" % line)

    buildfile.seek(0, os.SEEK_END)
    info = tarfile.TarInfo("Dockerfile")
    info.size = buildfile.tell()

    buildfile.seek(0)
    tar.addfile(info, fileobj=buildfile)

    tar.close()
    output.seek(0, os.SEEK_END)
    tar_size = output.tell()
    output.seek(0)

    return tar_size


def create_filesystem(staging_uri, s3_key, s3_secret):
    """Create an instance of a filesystem based on the URI"""

    url = urlparse(staging_uri)

    # Local filesystem
    if not url.scheme:
        return OSFS(
            root_path=url.path,
            create=True
        )

    # S3 filesystem
    if url.scheme.lower() == "s3":
        if not url.netloc:
            raise Exception("You must specify a s3://bucket/ when using s3")
        return S3FS(
            bucket=url.netloc,
            prefix=url.path,
            aws_access_key=s3_key,
            aws_secret_key=s3_secret,
            key_sync_timeout=3
        )


class Scheduler(mesos.Scheduler):
    """Mesos scheduler that is responsible for launching the builder tasks."""

    def __init__(self, task_queue, checkpoint, cpu_limit, mem_limit, args):
        self.task_queue = task_queue
        self.checkpoint_path = checkpoint
        self.cpu = cpu_limit
        self.mem = mem_limit
        self.args = args

        self.filesystem = create_filesystem(
            staging_uri=self.args.staging_uri,
            s3_key=self.args.s3_access_key,
            s3_secret=self.args.s3_secret_key
        )

    def registered(self, driver, frameworkId, masterInfo):
        logger.info("Framework registered with %s", frameworkId.value)
        self._checkpoint(frameworkId=frameworkId.value)

    def resourceOffers(self, driver, offers):

        if self.task_queue.empty():
            return

        logger.debug("Received %d offers", len(offers))

        for offer in offers:
            offer_cpu = 0.0
            offer_mem = 0

            for resource in offer.resources:
                if resource.name == "cpus":
                    offer_cpu = resource.scalar
                if resource.name == "mem":
                    offer_mem = resource.scalar

            # Launch the task if applicable
            if offer_cpu >= self.cpu and offer_mem >= self.mem:
                dockerfile = self.task_queue.get()

                thread = threading.Thread(
                    target=functools.partial(self._launchTask, dockerfile, offer)
                )

                thread.setDaemon(True)
                thread.start()
            else:
                logger.debug("Ignoring offer %r", offer)

    def _launchTask(self, dockerfile, offer):

        logger.info("Launching task to build %s", dockerfile)

        # Generate the dockerfile build context
        _, context_path = tempfile.mkstemp()
        context = open(context_path, "w+b")

        logger.debug("Writing context tar to %s", context_path)

        context_root = os.path.abspath(os.path.dirname(dockerfile))
        context_size = make_build_context(context, context_root, dockerfile)

        # Generate a task ID
        task_id = uuid.uuid1()

        # Upload the build context to the staging filesystem
        staging_file = "%s.tar.gz" % task_id
        staging_uri = os.path.join(self.args.staging_uri, staging_file)

        logger.info("Uploading context to %s (%d bytes)", staging_uri, context_size)

        # Create a progress bar
        pbar = progressbar.ProgressBar(maxval=context_size)
        event = self.filesystem.setcontents_async(
            path=staging_file,
            data=context,
            progress_callback=pbar.update,
            finished_callback=pbar.finish
        )

        # Wait for the file to upload...
        event.wait()

        # Close and clear up the tmp context
        logger.info("Cleaning up local context %s", context_path)
        context.close()
        os.unlink(context_path)

        # Launch the mesos task!

    def _checkpoint(self, frameworkId=None):
        """Helper method for persisting checkpoint information."""

        if not self.checkpoint_path:
            logger.debug("Skipping checkpoint, not enabled")
            return

        exists = os.path.exists(self.checkpoint_path)
        with open(self.checkpoint_path, "w+b") as cp:
            checkpoint = ddocker_pb2.Checkpoint()
            if exists:
                ddocker_pb2.Checkpoint.ParseFromString(checkpoint, cp.read())
                cp.seek(0)

            if frameworkId:
                checkpoint.frameworkId = frameworkId

            logger.debug("Written checkpoint to %s", self.checkpoint_path)

            cp.write(checkpoint.SerializeToString())
            cp.truncate()
